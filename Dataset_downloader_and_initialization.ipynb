{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset downloader and initialization**"
      ],
      "metadata": {
        "id": "EzAQJZ_xtBkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "70Ui4Fi1Krf5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9_fgB6KGv3y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlPBqOKEz2ff"
      },
      "outputs": [],
      "source": [
        "!pip install pyvww\n",
        "!git clone https://github.com/Mxbonn/visualwakewords"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have to open /content/visualwakewords/scripts/download_mscoco.sh and delete lines 74 and 75. Once you have done it, proceed with this:"
      ],
      "metadata": {
        "id": "6W5lqhDpvDgs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_DmOB7f03He"
      },
      "outputs": [],
      "source": [
        "!bash visualwakewords/scripts/download_mscoco.sh path-to-COCO-dataset 2014"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following cell once. It will give you an error, but it will create a new folder called -to-mscoco-dataset. You have to move the json files /content/path-to-COCO-dataset/annotations/instances_train2014.json and /content/path-to-COCO-dataset/annotations/instances_val2014.json into the folder /content/-to-mscoco-dataset/annotations . Once you have done it, rerun the same cell once again."
      ],
      "metadata": {
        "id": "_Bwmkt9dyJQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "er0i81no1tx_"
      },
      "outputs": [],
      "source": [
        "TRAIN_ANNOTATIONS_FILE=\"path-to-mscoco-dataset/annotations/instances_train2014.json\"\n",
        "VAL_ANNOTATIONS_FILE=\"path-to-mscoco-dataset/annotations/instances_val2014.json\"\n",
        "DIR=\"path-to-mscoco-dataset/annotations/\"\n",
        "!python visualwakewords/scripts/create_coco_train_minival_split.py \\\n",
        "  --train_annotations_file=\"${TRAIN_ANNOTATIONS_FILE}\" \\\n",
        "  --val_annotations_file=\"${VAL_ANNOTATIONS_FILE}\" \\\n",
        "--output_dir=\"${DIR}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHnt8m1f1uph"
      },
      "outputs": [],
      "source": [
        "MAXITRAIN_ANNOTATIONS_FILE=\"path-to-mscoco-dataset/annotations/instances_maxitrain.json\"\n",
        "MINIVAL_ANNOTATIONS_FILE=\"path-to-mscoco-dataset/annotations/instances_minival.json\"\n",
        "VWW_OUTPUT_DIR=\"new-path-to-visualwakewords-dataset/annotations/\"\n",
        "!python visualwakewords/scripts/create_visualwakewords_annotations.py \\\n",
        "  --train_annotations_file=\"${MAXITRAIN_ANNOTATIONS_FILE}\" \\\n",
        "  --val_annotations_file=\"${MINIVAL_ANNOTATIONS_FILE}\" \\\n",
        "  --output_dir=\"${VWW_OUTPUT_DIR}\" \\\n",
        "  --threshold=0.005 \\\n",
        "  --foreground_class='person'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw4dZWFvJjjj"
      },
      "outputs": [],
      "source": [
        "#RESIZE OF THE IMAGES\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "path_images = \"/content/path-to-COCO-dataset/train2014/\"\n",
        "for im in os.listdir(path_images):\n",
        "    path=path_images+im\n",
        "    im= Image.open(path)\n",
        "    im = im.resize((224,224))\n",
        "    im.save(path)\n",
        "\n",
        "path_images = \"/content/path-to-COCO-dataset/val2014/\"\n",
        "for im in os.listdir(path_images):\n",
        "    path=path_images+im\n",
        "    im= Image.open(path)\n",
        "    im = im.resize((224,224))\n",
        "    im.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert inside ***train_path*** the path to which you want to save the data in your drive (example: '/content/drive/MyDrive/Project4a/dataset/train2014.tar'):"
      ],
      "metadata": {
        "id": "IIqd35X60F9z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5Cp7M1s99_M"
      },
      "outputs": [],
      "source": [
        "!tar -cvf train_path /content/path-to-COCO-dataset/train2014/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert inside ***val_path*** the path to which you want to save the data in your drive (example: '/content/drive/MyDrive/Project4a/dataset/val2014.tar'):"
      ],
      "metadata": {
        "id": "qkIbAzgB02De"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7DJbA-H9-5N"
      },
      "outputs": [],
      "source": [
        "!tar -cvf val_path /content/path-to-COCO-dataset/val2014/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have completed the execution of all the script, you have to save the annotation files. To do this, you have to download the files /content/-to-mscoco-dataset/annotations/instances_train2014.json and /content/-to-mscoco-dataset/annotations/instances_val2014.json ."
      ],
      "metadata": {
        "id": "YcGkfvqD1Syh"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}